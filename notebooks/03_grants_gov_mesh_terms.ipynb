{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling Health Grant Descriptions with MeSH Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import spacy\n",
    "import textacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher, Matcher\n",
    "from spacy.tokens import Doc, Span, Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import health terms.\n",
    "2. Filter terms down to the desired level.\n",
    "3. Add them as patterns to the matcher, labelled by the terms in the highest category level desired.\n",
    "4. Add a token attribute to hold the category label, and create a callback function to update this attribute.\n",
    "5. Find matches in documents.\n",
    "\n",
    "- Stretch goal: associate terms using part of speech in a network or coocurrence matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import Health Terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/mesh_codes_processed_5_8_2018.json', 'r') as f:\n",
    "    health_terms = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Filter Terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(string):\n",
    "    string = string.split(', ')\n",
    "    string = ' '.join(string[::-1])\n",
    "    return string.lower()\n",
    "\n",
    "def filter_terms(terms, order, on='ConceptStringProcessed'):\n",
    "    filtered = {}\n",
    "    for tree_number, properties in terms.items():\n",
    "#         print(tree_number, properties)\n",
    "        if properties['tree_order'] >= order:\n",
    "#             if properties.get('tree_{}_{}'.format(on, order)) is not None:\n",
    "            top_parent = properties['tree_{}_{}'.format(on, order)]\n",
    "            names = list(set([process_string(properties['{}'.format(t)]) for t in ['TermString', 'ConceptNameString', 'DescriptorNameString']]))\n",
    "            for name in names:\n",
    "                filtered[name.lower()] = top_parent\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_terms_filtered = filter_terms(health_terms, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55183"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(health_terms_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Import Project Descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_grants = pd.read_csv('../data/processed/health_research_grants_4_26_2018.csv')\n",
    "\n",
    "n_docs = 200\n",
    "descriptions = health_grants.sample(n=200)['public_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 499 ms, sys: 4.11 ms, total: 503 ms\n",
      "Wall time: 504 ms\n"
     ]
    }
   ],
   "source": [
    "%time descriptions_clean = [textacy.preprocess_text(textacy.preprocess.fix_bad_unicode(d), lowercase=True) for d in descriptions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Create PhraseMatcher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.03 s, sys: 1.21 s, total: 6.24 s\n",
      "Wall time: 7.09 s\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "%time phrases = [(tokenizer(k), v) for k, v in health_terms_filtered.items()]\n",
    "\n",
    "for phrase, _ in phrases:\n",
    "    for token in phrase:\n",
    "        _ = tokenizer.vocab[token.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(tokenizer.vocab, max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 118 ms, sys: 9.36 ms, total: 127 ms\n",
      "Wall time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for phrase in phrases:\n",
    "    if phrase[1] is not None:\n",
    "        if len(phrase[0]) < 10:\n",
    "            matcher.add(phrase[1], None, phrase[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Add Token Attribute and Callback**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Find Matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 s, sys: 16.6 ms, total: 1.68 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "matches = []\n",
    "\n",
    "for text in descriptions_clean:\n",
    "    doc = tokenizer(text)\n",
    "#     for w in doc:\n",
    "#         _ = doc.vocab[w.text]\n",
    "    matches.append(matcher(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated time to execute matching on all documents: 0.5132933333333334 hours\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated time to execute matching on all documents:\", (0.5 + 7.1 + 0.2 + 1.8) * (len(health_grants) / n_docs) / 3600, 'hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take roughly half an hour to apply the current matching scheme to around 40,000 documents.\n",
    "\n",
    "The results here are pretty promising. I originally thought that there would be no matches in many documents, but it looks as if all documents have multiple matches. Perhaps the standardisation of language within the health and medical fields is pretty strong. One issue is words that are wrongly matched because they appear both in the MeSH terms and also in the documens, but clearly not in a medical sense. For example \"will\" is matched wherever it occurs as a \"psychological process\", which is clearly not going to be the case for many uses of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ====================================================================================================\n",
      "17520808660558581486\tpersons                                         \twomen\n",
      "4041061045944005301\tbehavioral disciplines and activities           \tmental health\n",
      "3742528541303202448\treproductive and urinary physiological phenomena\tpregnancy\n",
      "3742528541303202448\treproductive and urinary physiological phenomena\tpostpartum period\n",
      "1700477306715462547\tbehavior and behavior mechanisms                \tmood\n",
      "16986002624275872851\thealth occupations                              \tepidemiology\n",
      "1700477306715462547\tbehavior and behavior mechanisms                \trisk\n",
      "4508651938417329706\tphysical sciences                               \tneuroscience\n",
      "1700477306715462547\tbehavior and behavior mechanisms                \tmood\n",
      "413156896107774725\tsevere mental disorders                         \tmood disorders\n",
      "12114241926807388188\tpsychologic processes                           \twill\n",
      "737360591271645834\thumanities                                      \tawards\n",
      "12114241926807388188\tpsychologic processes                           \twill\n",
      "5243318514652091556\tnon-medical public and private facilities       \tuniversities\n",
      "7913546610620042517\tand services manpower health care facilities    \thospitals\n",
      "7913546610620042517\tand services manpower health care facilities    \tlaboratories\n",
      "5365852822977438211\thealth care economics and organizations         \tstate government\n",
      "5365852822977438211\thealth care economics and organizations         \tgovernment\n",
      "5365852822977438211\thealth care economics and organizations         \tlocal government\n",
      "5365852822977438211\thealth care economics and organizations         \tgovernment\n",
      "5365852822977438211\thealth care economics and organizations         \tfederal government\n",
      "5365852822977438211\thealth care economics and organizations         \tgovernment\n",
      "5365852822977438211\thealth care economics and organizations         \tgovernment\n",
      "5365852822977438211\thealth care economics and organizations         \tgovernment\n",
      "737360591271645834\thumanities                                      \tknowledge\n",
      "7563619441488496436\tand evaluation access health care quality       \tresources\n",
      "4877011699741374108\thuman activities                                \twork\n",
      "9866467026877975833\tpopulation heterogeneity                        \tethnic groups\n",
      "100 ====================================================================================================\n",
      "12114241926807388188\tpsychologic processes                           \twill\n",
      "12114241926807388188\tpsychologic processes                           \twill\n",
      "5888194563811241660\tpharmaceutical preparations                     \tsolutions\n",
      "10187473241180020316\tenvironment and public health                   \tair\n",
      "1700477306715462547\tbehavior and behavior mechanisms                \tleadership\n",
      "12114241926807388188\tpsychologic processes                           \twill\n",
      "10187473241180020316\tenvironment and public health                   \tfire\n",
      "10187473241180020316\tenvironment and public health                   \tfire\n",
      "15207787584408154854\tinformation science                             \tmobile phone\n",
      "7027329261096839145\tsocial sciences                                 \tterrorism\n",
      "7913546610620042517\tand services manpower health care facilities    \tmaintenance\n",
      "10187473241180020316\tenvironment and public health                   \temergency\n",
      "12114241926807388188\tpsychologic processes                           \twill\n",
      "12114241926807388188\tpsychologic processes                           \twill\n",
      "17520808660558581486\tpersons                                         \tclients\n"
     ]
    }
   ],
   "source": [
    "for i, match in enumerate(matches):\n",
    "    if i in [0, 100]:\n",
    "        print(i, '='*100)\n",
    "        for match_id, start, end in match:\n",
    "            string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "            span = docs[i][start:end]  # the matched span\n",
    "            print('{:<16}\\t{:<48}\\t{}'.format(match_id, string_id, span.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible Improvements**\n",
    "\n",
    "1. Enhance the list of terms by splitting into unigrams and filtering both the most uncommon and most common. Manually check for terms that are sufficiently appropriate in each category.\n",
    "2. Use POS tagging to stop tagging words that are not used in a medical sense, e.g. \"will\". It seems like all of the MeSH terms are nouns, but I could be wrong...\n",
    "3. Use word vectors to match synonmyms with a very close similarity (maybe it would be better to just enhance the initial list of terms).\n",
    "\n",
    "**Think About**\n",
    "- Best way to use the transformed documents - clustering vs network.\n",
    "- Whether there's a computationally efficient way to find similar words within a document (probably most efficient just to stick with spaCy's PhraseMatcher)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
